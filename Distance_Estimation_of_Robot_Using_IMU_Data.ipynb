{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BanerjeeProdipta/API_CRUD/blob/master/Distance_Estimation_of_Robot_Using_IMU_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/Colab Notebooks\n",
        "!ls"
      ],
      "metadata": {
        "id": "GJCJBpkJjjvJ",
        "outputId": "ebf0e82a-beaa-46c9-e753-215dc6752a28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Colab Notebooks\n",
            " amazon.csv\t\t  E-Commerce.ipynb\t\t\t  online_shoppers_intention.csv\n",
            "'amazon scrapper.ipynb'   glass.data\t\t\t\t 'Recommender System.ipynb'\n",
            " bestbuy.csv\t\t 'IMU dataset-20241113T171518Z-001.zip'   scaperToRecomanndation.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdSMoFVmUP4a",
        "outputId": "766dd593-805f-4b4d-8f28-411dc717b68d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  IMU dataset-20241113T171518Z-001.zip\n",
            "  inflating: IMU dataset/Curve_fast-2024-10-16_21-43-07.zip  \n",
            "  inflating: IMU dataset/Curve_slow-2024-10-16_21-38-29.zip  \n",
            "  inflating: IMU dataset/Straight_slow-2024-10-16_21-29-36.zip  \n",
            "  inflating: IMU dataset/Straight_fast-2024-10-16_21-34-59.zip  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"IMU dataset-20241113T171518Z-001.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"IMU dataset\"\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcybEenFUtIO",
        "outputId": "59ef8f7d-c9fd-45e6-b585-54131adc7225"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/IMU dataset\n",
            "Curve_fast-2024-10-16_21-43-07.zip  Straight_fast-2024-10-16_21-34-59.zip\n",
            "Curve_slow-2024-10-16_21-38-29.zip  Straight_slow-2024-10-16_21-29-36.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# Define a list of zip files and their corresponding prefixes\n",
        "zips_and_prefixes = [\n",
        "    (\"Curve_fast-2024-10-16_21-43-07.zip\", \"Curve_fast\"),\n",
        "    (\"Curve_slow-2024-10-16_21-38-29.zip\", \"Curve_slow\"),\n",
        "    (\"Straight_slow-2024-10-16_21-29-36.zip\", \"Straight_slow\"),\n",
        "    (\"Straight_fast-2024-10-16_21-34-59.zip\", \"Straight_fast\")\n",
        "]\n",
        "\n",
        "# Unzip files and rename CSVs with prefix\n",
        "for zip_file, prefix in zips_and_prefixes:\n",
        "    print(f\"\\nProcessing {zip_file}...\")\n",
        "\n",
        "    # Create a temporary directory for extraction\n",
        "    extraction_dir = f\"./extracted_{prefix}\"\n",
        "    os.makedirs(extraction_dir, exist_ok=True)\n",
        "\n",
        "    # Unzip the file into the extraction directory\n",
        "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extraction_dir)\n",
        "\n",
        "    # Rename extracted CSV files with the given prefix\n",
        "    for filename in os.listdir(extraction_dir):\n",
        "        if filename.endswith('.csv'):\n",
        "            new_filename = f\"{prefix}_{filename}\"\n",
        "            os.rename(os.path.join(extraction_dir, filename), new_filename)\n",
        "            print(f\"Renamed: {filename} -> {new_filename}\")\n",
        "\n",
        "    # Clean up the extraction directory\n",
        "    shutil.rmtree(extraction_dir)\n",
        "\n",
        "# List all renamed files to verify\n",
        "print(\"\\nFinal list of renamed files:\")\n",
        "!ls *.csv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj3cc5qYU1mW",
        "outputId": "ce21d730-a0d3-4cef-c493-45b52ef91a89"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing Curve_fast-2024-10-16_21-43-07.zip...\n",
            "Renamed: Straight_fast_Metadata.csv -> Curve_fast_Straight_fast_Metadata.csv\n",
            "Renamed: Straight_fast_Accelerometer.csv -> Curve_fast_Straight_fast_Accelerometer.csv\n",
            "Renamed: Straight_fast_Gravity.csv -> Curve_fast_Straight_fast_Gravity.csv\n",
            "Renamed: Straight_fast_Gyroscope.csv -> Curve_fast_Straight_fast_Gyroscope.csv\n",
            "Renamed: Straight_fast_Orientation.csv -> Curve_fast_Straight_fast_Orientation.csv\n",
            "Renamed: Straight_fast_Annotation.csv -> Curve_fast_Straight_fast_Annotation.csv\n",
            "Renamed: Straight_fast_TotalAcceleration.csv -> Curve_fast_Straight_fast_TotalAcceleration.csv\n",
            "Renamed: Straight_fast_Straight_slow_Curve_slow_Curve_fast_Metadata.csv -> Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Metadata.csv\n",
            "Renamed: Straight_fast_Straight_slow_Curve_slow_Curve_fast_Accelerometer.csv -> Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Accelerometer.csv\n",
            "Renamed: Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gravity.csv -> Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gravity.csv\n",
            "Renamed: Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gyroscope.csv -> Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gyroscope.csv\n",
            "Renamed: Straight_fast_Straight_slow_Curve_slow_Curve_fast_Orientation.csv -> Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Orientation.csv\n",
            "Renamed: Straight_fast_Straight_slow_Curve_slow_Curve_fast_Annotation.csv -> Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Annotation.csv\n",
            "Renamed: Straight_fast_Straight_slow_Curve_slow_Curve_fast_TotalAcceleration.csv -> Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_TotalAcceleration.csv\n",
            "Renamed: Straight_fast_Straight_slow_Curve_slow_Metadata.csv -> Curve_fast_Straight_fast_Straight_slow_Curve_slow_Metadata.csv\n",
            "Renamed: Straight_fast_Straight_slow_Curve_slow_Accelerometer.csv -> Curve_fast_Straight_fast_Straight_slow_Curve_slow_Accelerometer.csv\n",
            "Renamed: Straight_fast_Straight_slow_Curve_slow_Gravity.csv -> Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gravity.csv\n",
            "Renamed: Straight_fast_Straight_slow_Curve_slow_Gyroscope.csv -> Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gyroscope.csv\n",
            "Renamed: Straight_fast_Straight_slow_Curve_slow_Orientation.csv -> Curve_fast_Straight_fast_Straight_slow_Curve_slow_Orientation.csv\n",
            "Renamed: Straight_fast_Straight_slow_Curve_slow_Annotation.csv -> Curve_fast_Straight_fast_Straight_slow_Curve_slow_Annotation.csv\n",
            "Renamed: Straight_fast_Straight_slow_Curve_slow_TotalAcceleration.csv -> Curve_fast_Straight_fast_Straight_slow_Curve_slow_TotalAcceleration.csv\n",
            "Renamed: Straight_fast_Straight_slow_Accelerometer.csv -> Curve_fast_Straight_fast_Straight_slow_Accelerometer.csv\n",
            "Renamed: Straight_fast_Straight_slow_Metadata.csv -> Curve_fast_Straight_fast_Straight_slow_Metadata.csv\n",
            "Renamed: Straight_fast_Straight_slow_Gravity.csv -> Curve_fast_Straight_fast_Straight_slow_Gravity.csv\n",
            "Renamed: Straight_fast_Straight_slow_Gyroscope.csv -> Curve_fast_Straight_fast_Straight_slow_Gyroscope.csv\n",
            "Renamed: Straight_fast_Straight_slow_Orientation.csv -> Curve_fast_Straight_fast_Straight_slow_Orientation.csv\n",
            "Renamed: Straight_fast_Straight_slow_Annotation.csv -> Curve_fast_Straight_fast_Straight_slow_Annotation.csv\n",
            "Renamed: Straight_fast_Straight_slow_TotalAcceleration.csv -> Curve_fast_Straight_fast_Straight_slow_TotalAcceleration.csv\n",
            "Renamed: Metadata.csv -> Curve_fast_Metadata.csv\n",
            "Renamed: Accelerometer.csv -> Curve_fast_Accelerometer.csv\n",
            "Renamed: Gravity.csv -> Curve_fast_Gravity.csv\n",
            "Renamed: Gyroscope.csv -> Curve_fast_Gyroscope.csv\n",
            "Renamed: Orientation.csv -> Curve_fast_Orientation.csv\n",
            "Renamed: Annotation.csv -> Curve_fast_Annotation.csv\n",
            "Renamed: TotalAcceleration.csv -> Curve_fast_TotalAcceleration.csv\n",
            "\n",
            "Processing Curve_slow-2024-10-16_21-38-29.zip...\n",
            "Renamed: Curve_fast_Straight_fast_Metadata.csv -> Curve_slow_Curve_fast_Straight_fast_Metadata.csv\n",
            "Renamed: Curve_fast_Straight_fast_Accelerometer.csv -> Curve_slow_Curve_fast_Straight_fast_Accelerometer.csv\n",
            "Renamed: Curve_fast_Straight_fast_Gravity.csv -> Curve_slow_Curve_fast_Straight_fast_Gravity.csv\n",
            "Renamed: Curve_fast_Straight_fast_Gyroscope.csv -> Curve_slow_Curve_fast_Straight_fast_Gyroscope.csv\n",
            "Renamed: Curve_fast_Straight_fast_Orientation.csv -> Curve_slow_Curve_fast_Straight_fast_Orientation.csv\n",
            "Renamed: Curve_fast_Straight_fast_Annotation.csv -> Curve_slow_Curve_fast_Straight_fast_Annotation.csv\n",
            "Renamed: Curve_fast_Straight_fast_TotalAcceleration.csv -> Curve_slow_Curve_fast_Straight_fast_TotalAcceleration.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Metadata.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Metadata.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Accelerometer.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Accelerometer.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gravity.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gravity.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gyroscope.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gyroscope.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Orientation.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Orientation.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Annotation.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Annotation.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_TotalAcceleration.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_TotalAcceleration.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Curve_slow_Metadata.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Metadata.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Curve_slow_Accelerometer.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Accelerometer.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gravity.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gravity.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gyroscope.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gyroscope.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Curve_slow_Orientation.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Orientation.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Curve_slow_Annotation.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Annotation.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Curve_slow_TotalAcceleration.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_TotalAcceleration.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Accelerometer.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Accelerometer.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Metadata.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Metadata.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Gravity.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Gravity.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Gyroscope.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Gyroscope.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Orientation.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Orientation.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_Annotation.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_Annotation.csv\n",
            "Renamed: Curve_fast_Straight_fast_Straight_slow_TotalAcceleration.csv -> Curve_slow_Curve_fast_Straight_fast_Straight_slow_TotalAcceleration.csv\n",
            "Renamed: Metadata.csv -> Curve_slow_Metadata.csv\n",
            "Renamed: Accelerometer.csv -> Curve_slow_Accelerometer.csv\n",
            "Renamed: Gravity.csv -> Curve_slow_Gravity.csv\n",
            "Renamed: Gyroscope.csv -> Curve_slow_Gyroscope.csv\n",
            "Renamed: Orientation.csv -> Curve_slow_Orientation.csv\n",
            "Renamed: Annotation.csv -> Curve_slow_Annotation.csv\n",
            "Renamed: TotalAcceleration.csv -> Curve_slow_TotalAcceleration.csv\n",
            "Renamed: Curve_fast_Metadata.csv -> Curve_slow_Curve_fast_Metadata.csv\n",
            "Renamed: Curve_fast_Accelerometer.csv -> Curve_slow_Curve_fast_Accelerometer.csv\n",
            "Renamed: Curve_fast_Gravity.csv -> Curve_slow_Curve_fast_Gravity.csv\n",
            "Renamed: Curve_fast_Gyroscope.csv -> Curve_slow_Curve_fast_Gyroscope.csv\n",
            "Renamed: Curve_fast_Orientation.csv -> Curve_slow_Curve_fast_Orientation.csv\n",
            "Renamed: Curve_fast_Annotation.csv -> Curve_slow_Curve_fast_Annotation.csv\n",
            "Renamed: Curve_fast_TotalAcceleration.csv -> Curve_slow_Curve_fast_TotalAcceleration.csv\n",
            "\n",
            "Processing Straight_slow-2024-10-16_21-29-36.zip...\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Metadata.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Metadata.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Accelerometer.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Accelerometer.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Gravity.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Gravity.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Gyroscope.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Gyroscope.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Orientation.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Orientation.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Annotation.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Annotation.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_TotalAcceleration.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_TotalAcceleration.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Metadata.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Metadata.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Accelerometer.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Accelerometer.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gravity.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gravity.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gyroscope.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gyroscope.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Orientation.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Orientation.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Annotation.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Annotation.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_TotalAcceleration.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_TotalAcceleration.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Metadata.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Metadata.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Accelerometer.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Accelerometer.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gravity.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gravity.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gyroscope.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gyroscope.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Orientation.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Orientation.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Annotation.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Annotation.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_TotalAcceleration.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_TotalAcceleration.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Accelerometer.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Accelerometer.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Metadata.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Metadata.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Gravity.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Gravity.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Gyroscope.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Gyroscope.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Orientation.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Orientation.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_Annotation.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Annotation.csv\n",
            "Renamed: Curve_slow_Curve_fast_Straight_fast_Straight_slow_TotalAcceleration.csv -> Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_TotalAcceleration.csv\n",
            "Renamed: Metadata.csv -> Straight_slow_Metadata.csv\n",
            "Renamed: Accelerometer.csv -> Straight_slow_Accelerometer.csv\n",
            "Renamed: Gravity.csv -> Straight_slow_Gravity.csv\n",
            "Renamed: Gyroscope.csv -> Straight_slow_Gyroscope.csv\n",
            "Renamed: Orientation.csv -> Straight_slow_Orientation.csv\n",
            "Renamed: Annotation.csv -> Straight_slow_Annotation.csv\n",
            "Renamed: TotalAcceleration.csv -> Straight_slow_TotalAcceleration.csv\n",
            "Renamed: Curve_slow_Curve_fast_Metadata.csv -> Straight_slow_Curve_slow_Curve_fast_Metadata.csv\n",
            "Renamed: Curve_slow_Curve_fast_Accelerometer.csv -> Straight_slow_Curve_slow_Curve_fast_Accelerometer.csv\n",
            "Renamed: Curve_slow_Curve_fast_Gravity.csv -> Straight_slow_Curve_slow_Curve_fast_Gravity.csv\n",
            "Renamed: Curve_slow_Curve_fast_Gyroscope.csv -> Straight_slow_Curve_slow_Curve_fast_Gyroscope.csv\n",
            "Renamed: Curve_slow_Curve_fast_Orientation.csv -> Straight_slow_Curve_slow_Curve_fast_Orientation.csv\n",
            "Renamed: Curve_slow_Curve_fast_Annotation.csv -> Straight_slow_Curve_slow_Curve_fast_Annotation.csv\n",
            "Renamed: Curve_slow_Curve_fast_TotalAcceleration.csv -> Straight_slow_Curve_slow_Curve_fast_TotalAcceleration.csv\n",
            "Renamed: Curve_slow_Metadata.csv -> Straight_slow_Curve_slow_Metadata.csv\n",
            "Renamed: Curve_slow_Accelerometer.csv -> Straight_slow_Curve_slow_Accelerometer.csv\n",
            "Renamed: Curve_slow_Gravity.csv -> Straight_slow_Curve_slow_Gravity.csv\n",
            "Renamed: Curve_slow_Gyroscope.csv -> Straight_slow_Curve_slow_Gyroscope.csv\n",
            "Renamed: Curve_slow_Orientation.csv -> Straight_slow_Curve_slow_Orientation.csv\n",
            "Renamed: Curve_slow_Annotation.csv -> Straight_slow_Curve_slow_Annotation.csv\n",
            "Renamed: Curve_slow_TotalAcceleration.csv -> Straight_slow_Curve_slow_TotalAcceleration.csv\n",
            "\n",
            "Processing Straight_fast-2024-10-16_21-34-59.zip...\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Metadata.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Metadata.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Accelerometer.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Accelerometer.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Gravity.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Gravity.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Gyroscope.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Gyroscope.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Orientation.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Orientation.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Annotation.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Annotation.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_TotalAcceleration.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_TotalAcceleration.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Metadata.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Metadata.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Accelerometer.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Accelerometer.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gravity.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gravity.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gyroscope.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gyroscope.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Orientation.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Orientation.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Annotation.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Annotation.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_TotalAcceleration.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_TotalAcceleration.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Metadata.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Metadata.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Accelerometer.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Accelerometer.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gravity.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gravity.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gyroscope.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gyroscope.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Orientation.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Orientation.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Annotation.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Annotation.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_TotalAcceleration.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_TotalAcceleration.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Accelerometer.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Accelerometer.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Metadata.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Metadata.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Gravity.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Gravity.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Gyroscope.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Gyroscope.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Orientation.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Orientation.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Annotation.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Annotation.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_TotalAcceleration.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_TotalAcceleration.csv\n",
            "Renamed: Metadata.csv -> Straight_fast_Metadata.csv\n",
            "Renamed: Accelerometer.csv -> Straight_fast_Accelerometer.csv\n",
            "Renamed: Gravity.csv -> Straight_fast_Gravity.csv\n",
            "Renamed: Gyroscope.csv -> Straight_fast_Gyroscope.csv\n",
            "Renamed: Orientation.csv -> Straight_fast_Orientation.csv\n",
            "Renamed: Annotation.csv -> Straight_fast_Annotation.csv\n",
            "Renamed: TotalAcceleration.csv -> Straight_fast_TotalAcceleration.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Metadata.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Metadata.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Accelerometer.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Accelerometer.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Gravity.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gravity.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Gyroscope.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gyroscope.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Orientation.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Orientation.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_Annotation.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_Annotation.csv\n",
            "Renamed: Straight_slow_Curve_slow_Curve_fast_TotalAcceleration.csv -> Straight_fast_Straight_slow_Curve_slow_Curve_fast_TotalAcceleration.csv\n",
            "Renamed: Straight_slow_Curve_slow_Metadata.csv -> Straight_fast_Straight_slow_Curve_slow_Metadata.csv\n",
            "Renamed: Straight_slow_Curve_slow_Accelerometer.csv -> Straight_fast_Straight_slow_Curve_slow_Accelerometer.csv\n",
            "Renamed: Straight_slow_Curve_slow_Gravity.csv -> Straight_fast_Straight_slow_Curve_slow_Gravity.csv\n",
            "Renamed: Straight_slow_Curve_slow_Gyroscope.csv -> Straight_fast_Straight_slow_Curve_slow_Gyroscope.csv\n",
            "Renamed: Straight_slow_Curve_slow_Orientation.csv -> Straight_fast_Straight_slow_Curve_slow_Orientation.csv\n",
            "Renamed: Straight_slow_Curve_slow_Annotation.csv -> Straight_fast_Straight_slow_Curve_slow_Annotation.csv\n",
            "Renamed: Straight_slow_Curve_slow_TotalAcceleration.csv -> Straight_fast_Straight_slow_Curve_slow_TotalAcceleration.csv\n",
            "Renamed: Straight_slow_Accelerometer.csv -> Straight_fast_Straight_slow_Accelerometer.csv\n",
            "Renamed: Straight_slow_Metadata.csv -> Straight_fast_Straight_slow_Metadata.csv\n",
            "Renamed: Straight_slow_Gravity.csv -> Straight_fast_Straight_slow_Gravity.csv\n",
            "Renamed: Straight_slow_Gyroscope.csv -> Straight_fast_Straight_slow_Gyroscope.csv\n",
            "Renamed: Straight_slow_Orientation.csv -> Straight_fast_Straight_slow_Orientation.csv\n",
            "Renamed: Straight_slow_Annotation.csv -> Straight_fast_Straight_slow_Annotation.csv\n",
            "Renamed: Straight_slow_TotalAcceleration.csv -> Straight_fast_Straight_slow_TotalAcceleration.csv\n",
            "\n",
            "Renamed files:\n",
            "Straight_fast_Accelerometer.csv\n",
            "Straight_fast_Annotation.csv\n",
            "Straight_fast_Gravity.csv\n",
            "Straight_fast_Gyroscope.csv\n",
            "Straight_fast_Metadata.csv\n",
            "Straight_fast_Orientation.csv\n",
            "Straight_fast_Straight_slow_Accelerometer.csv\n",
            "Straight_fast_Straight_slow_Annotation.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Accelerometer.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Annotation.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Accelerometer.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Annotation.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gravity.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gyroscope.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Metadata.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Orientation.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Accelerometer.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Annotation.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Gravity.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Gyroscope.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Metadata.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Orientation.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Accelerometer.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Annotation.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Accelerometer.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Annotation.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Accelerometer.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Annotation.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gravity.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Gyroscope.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Metadata.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_Orientation.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Curve_fast_TotalAcceleration.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gravity.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Gyroscope.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Metadata.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_Orientation.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Curve_slow_TotalAcceleration.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Gravity.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Gyroscope.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Metadata.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_Orientation.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_Straight_slow_TotalAcceleration.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_Straight_fast_TotalAcceleration.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Curve_fast_TotalAcceleration.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Gravity.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Gyroscope.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Metadata.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_Orientation.csv\n",
            "Straight_fast_Straight_slow_Curve_slow_TotalAcceleration.csv\n",
            "Straight_fast_Straight_slow_Gravity.csv\n",
            "Straight_fast_Straight_slow_Gyroscope.csv\n",
            "Straight_fast_Straight_slow_Metadata.csv\n",
            "Straight_fast_Straight_slow_Orientation.csv\n",
            "Straight_fast_Straight_slow_TotalAcceleration.csv\n",
            "Straight_fast_TotalAcceleration.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZK6M8nJa1MS",
        "outputId": "e5c95bad-0e5f-4d37-a7fb-b98576d3f940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accelerometer.csv  Gravity.csv\t  Metadata.csv\t   TotalAcceleration.csv\n",
            "Annotation.csv\t   Gyroscope.csv  Orientation.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/IMU-dataset/Straight_fast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7lHBcV0b0ZL",
        "outputId": "600a2e47-13e9-41cb-c449-c8fddaa4ae5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/IMU-dataset/Straight_fast\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/IMU-dataset/Straight_fast-2024-10-16_21-34-59.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq2VbloEcFDs",
        "outputId": "dba41f97-04fc-4946-b27c-d62ee07891b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/IMU-dataset/Straight_fast-2024-10-16_21-34-59.zip\n",
            "  inflating: Accelerometer.csv       \n",
            "  inflating: Metadata.csv            \n",
            "  inflating: Gravity.csv             \n",
            "  inflating: Gyroscope.csv           \n",
            "  inflating: Orientation.csv         \n",
            " extracting: Annotation.csv          \n",
            "  inflating: TotalAcceleration.csv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/IMU-dataset/Straight_slow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyk2eOCocKV2",
        "outputId": "1678b198-88d0-4d82-cfd1-9e99a1de3f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/IMU-dataset/Straight_slow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/IMU-dataset/Straight_slow-2024-10-16_21-29-36.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btO_lF6TcP_z",
        "outputId": "ae905c21-07a7-4570-9380-3748b7404b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/IMU-dataset/Straight_slow-2024-10-16_21-29-36.zip\n",
            "  inflating: Metadata.csv            \n",
            "  inflating: Accelerometer.csv       \n",
            "  inflating: Gravity.csv             \n",
            "  inflating: Gyroscope.csv           \n",
            "  inflating: Orientation.csv         \n",
            " extracting: Annotation.csv          \n",
            "  inflating: TotalAcceleration.csv   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the base directory where the data folders are stored\n",
        "base_dir = '/content/IMU-dataset'\n",
        "motion_types = ['Curve_fast', 'Curve_slow', 'Straight_fast', 'Straight_slow']\n",
        "sensor_files = ['Accelerometer.csv', 'Gravity.csv', 'Gyroscope.csv', 'Orientation.csv', 'Annotation.csv', 'TotalAcceleration.csv']\n",
        "\n",
        "# Dictionary to store combined DataFrames for each sensor type\n",
        "data = {sensor: [] for sensor in sensor_files}\n",
        "\n",
        "# Load and label data for each motion type\n",
        "for motion in motion_types:\n",
        "    # Path to the motion type directory\n",
        "    motion_dir = os.path.join(base_dir, motion)\n",
        "\n",
        "    for sensor in sensor_files:\n",
        "        # Construct the file path for each sensor file in the motion directory\n",
        "        file_path = os.path.join(motion_dir, sensor)\n",
        "\n",
        "        # Check if file exists to handle any missing files gracefully\n",
        "        if os.path.exists(file_path):\n",
        "            try:\n",
        "                # Load CSV file\n",
        "                df = pd.read_csv(file_path)\n",
        "\n",
        "                # If file is empty, skip to avoid errors\n",
        "                if df.empty:\n",
        "                    print(f\"Warning: {file_path} is empty. Skipping.\")\n",
        "                    continue\n",
        "\n",
        "                # Add a column to label the motion type\n",
        "                df['motion_type'] = motion\n",
        "\n",
        "                # Append to the corresponding sensor's data list\n",
        "                data[sensor].append(df)\n",
        "\n",
        "            except pd.errors.EmptyDataError:\n",
        "                # Catch and handle empty data error explicitly\n",
        "                print(f\"Warning: {file_path} is empty or unreadable. Skipping.\")\n",
        "        else:\n",
        "            print(f\"Warning: {file_path} does not exist.\")\n",
        "\n",
        "# Concatenate data from all motion types for each sensor into a single DataFrame\n",
        "for sensor in sensor_files:\n",
        "    if data[sensor]:  # Only concatenate if there's data for this sensor\n",
        "        data[sensor] = pd.concat(data[sensor], ignore_index=True)\n",
        "    else:\n",
        "        print(f\"Warning: No data found for {sensor} across all motion types.\")\n",
        "        data[sensor] = pd.DataFrame()  # Assign an empty DataFrame for consistency\n",
        "\n",
        "# Example: Display the first few rows of Accelerometer data if available\n",
        "if 'Accelerometer.csv' in data and not data['Accelerometer.csv'].empty:\n",
        "    print(\"Accelerometer Data Sample:\")\n",
        "    print(data['Accelerometer.csv'].head())\n",
        "\n",
        "# Summary statistics and missing values check for each sensor\n",
        "for sensor in sensor_files:\n",
        "    if isinstance(data[sensor], pd.DataFrame) and not data[sensor].empty:\n",
        "        print(f\"\\nSummary for {sensor}:\")\n",
        "        print(data[sensor].describe())\n",
        "        print(f\"\\nMissing values in {sensor}:\")\n",
        "        print(data[sensor].isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCfeQcpUap8A",
        "outputId": "41616895-1b73-4737-e851-ad7d107f1240"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: /content/IMU-dataset/Curve_fast/Annotation.csv is empty or unreadable. Skipping.\n",
            "Warning: /content/IMU-dataset/Curve_slow/Annotation.csv is empty or unreadable. Skipping.\n",
            "Warning: /content/IMU-dataset/Straight_fast/Annotation.csv is empty or unreadable. Skipping.\n",
            "Warning: /content/IMU-dataset/Straight_slow/Annotation.csv is empty or unreadable. Skipping.\n",
            "Warning: No data found for Annotation.csv across all motion types.\n",
            "Accelerometer Data Sample:\n",
            "                  time  seconds_elapsed         z         y         x  \\\n",
            "0  1729114987950340400         0.028340  0.000000  0.000000  0.000000   \n",
            "1  1729114987987895800         0.065896  0.001596  0.005874 -0.011253   \n",
            "2  1729114988025830400         0.103830  0.044533 -0.006611  0.016885   \n",
            "3  1729114988063764700         0.141765 -0.041039 -0.010302 -0.018762   \n",
            "4  1729114988101699300         0.179699  0.039904 -0.030601  0.003223   \n",
            "\n",
            "  motion_type  \n",
            "0  Curve_fast  \n",
            "1  Curve_fast  \n",
            "2  Curve_fast  \n",
            "3  Curve_fast  \n",
            "4  Curve_fast  \n",
            "\n",
            "Summary for Accelerometer.csv:\n",
            "               time  seconds_elapsed             z             y             x\n",
            "count  1.123600e+04     11236.000000  11236.000000  11236.000000  11236.000000\n",
            "mean   1.729115e+18        53.485611     -0.010594     -0.233601     -0.008155\n",
            "std    3.010541e+11        31.035867      1.404290      0.817849      0.928250\n",
            "min    1.729114e+18         0.025945     -8.904371     -6.065255     -9.084266\n",
            "25%    1.729115e+18        26.690785     -0.141685     -0.564070     -0.206954\n",
            "50%    1.729115e+18        53.324774      0.000275     -0.005425     -0.005375\n",
            "75%    1.729115e+18        79.958768      0.172254      0.105341      0.145833\n",
            "max    1.729115e+18       112.982851     12.360336      7.574972      9.688910\n",
            "\n",
            "Missing values in Accelerometer.csv:\n",
            "time               0\n",
            "seconds_elapsed    0\n",
            "z                  0\n",
            "y                  0\n",
            "x                  0\n",
            "motion_type        0\n",
            "dtype: int64\n",
            "\n",
            "Summary for Gravity.csv:\n",
            "               time  seconds_elapsed             z             y             x\n",
            "count  1.123600e+04     11236.000000  11236.000000  11236.000000  11236.000000\n",
            "mean   1.729115e+18        53.485611      9.795508      0.086459     -0.138918\n",
            "std    3.010541e+11        31.035867      0.014387      0.377456      0.221302\n",
            "min    1.729114e+18         0.025945      9.609606     -1.283242     -1.476192\n",
            "25%    1.729115e+18        26.690785      9.792547     -0.149722     -0.225257\n",
            "50%    1.729115e+18        53.324774      9.801188     -0.034145     -0.156342\n",
            "75%    1.729115e+18        79.958768      9.804543      0.335289     -0.064565\n",
            "max    1.729115e+18       112.982851      9.806650      1.326082      0.786790\n",
            "\n",
            "Missing values in Gravity.csv:\n",
            "time               0\n",
            "seconds_elapsed    0\n",
            "z                  0\n",
            "y                  0\n",
            "x                  0\n",
            "motion_type        0\n",
            "dtype: int64\n",
            "\n",
            "Summary for Gyroscope.csv:\n",
            "               time  seconds_elapsed             z             y             x\n",
            "count  1.278300e+04     12783.000000  12783.000000  12783.000000  12783.000000\n",
            "mean   1.729115e+18        53.497151     -0.178000      0.000197     -0.002934\n",
            "std    3.010557e+11        31.025476      0.898581      0.065300      0.044669\n",
            "min    1.729114e+18         0.053758     -3.583535     -1.000873     -0.679262\n",
            "25%    1.729115e+18        26.705901     -0.110143     -0.007559     -0.005956\n",
            "50%    1.729115e+18        53.332014     -0.000153      0.000000      0.000000\n",
            "75%    1.729115e+18        79.964403      0.010919      0.008399      0.012446\n",
            "max    1.729115e+18       112.978729      3.565744      1.046305      0.659562\n",
            "\n",
            "Missing values in Gyroscope.csv:\n",
            "time               0\n",
            "seconds_elapsed    0\n",
            "z                  0\n",
            "y                  0\n",
            "x                  0\n",
            "motion_type        0\n",
            "dtype: int64\n",
            "\n",
            "Summary for Orientation.csv:\n",
            "               time  seconds_elapsed           qz           qy           qx  \\\n",
            "count  7.656000e+03      7656.000000  7656.000000  7656.000000  7656.000000   \n",
            "mean   1.729115e+18        53.625335     0.164294     0.006117     0.010105   \n",
            "std    3.012629e+11        30.971426     0.699780     0.026304     0.027003   \n",
            "min    1.729114e+18         0.103007    -0.999799    -0.079694    -0.067564   \n",
            "25%    1.729115e+18        26.890367    -0.554667    -0.006446    -0.008556   \n",
            "50%    1.729115e+18        53.458548     0.500474     0.002275     0.004685   \n",
            "75%    1.729115e+18        80.048630     0.838815     0.017385     0.024893   \n",
            "max    1.729115e+18       113.010811     0.999737     0.071667     0.092377   \n",
            "\n",
            "                qw         roll        pitch          yaw  \n",
            "count  7656.000000  7656.000000  7656.000000  7656.000000  \n",
            "mean      0.663692     0.015881    -0.029245    -0.447969  \n",
            "std       0.203316     0.032073     0.064161     1.652188  \n",
            "min       0.001621    -0.119757    -0.186254    -3.138554  \n",
            "25%       0.527331     0.004498    -0.078709    -1.995198  \n",
            "50%       0.672081     0.015947    -0.012395    -1.048357  \n",
            "75%       0.833602     0.024853     0.008907     1.177157  \n",
            "max       0.999948     0.168265     0.198058     3.138069  \n",
            "\n",
            "Missing values in Orientation.csv:\n",
            "time               0\n",
            "seconds_elapsed    0\n",
            "qz                 0\n",
            "qy                 0\n",
            "qx                 0\n",
            "qw                 0\n",
            "roll               0\n",
            "pitch              0\n",
            "yaw                0\n",
            "motion_type        0\n",
            "dtype: int64\n",
            "\n",
            "Summary for TotalAcceleration.csv:\n",
            "               time  seconds_elapsed             z             y             x\n",
            "count  1.123500e+04     11235.000000  11235.000000  11235.000000  11235.000000\n",
            "mean   1.729115e+18        53.495470      9.887244     -0.144926     -0.144402\n",
            "std    3.010952e+11        31.033305      1.415548      0.908907      1.017478\n",
            "min    1.729114e+18         0.068879     -0.369392     -6.102296     -9.923335\n",
            "25%    1.729115e+18        26.702372      9.748060     -0.480957     -0.315853\n",
            "50%    1.729115e+18        53.336044      9.896416     -0.081057     -0.162712\n",
            "75%    1.729115e+18        79.968831     10.059426      0.119940      0.035892\n",
            "max    1.729115e+18       113.006818     22.333710      7.295118     10.088738\n",
            "\n",
            "Missing values in TotalAcceleration.csv:\n",
            "time               0\n",
            "seconds_elapsed    0\n",
            "z                  0\n",
            "y                  0\n",
            "x                  0\n",
            "motion_type        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Function to normalize the sensor data\n",
        "def normalize_data(df):\n",
        "    scaler = MinMaxScaler()\n",
        "    return pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# Normalize the data for 'x', 'y', 'z'\n",
        "def normalize_step(sensor_data):\n",
        "    print(\"Step 1: Normalization\")\n",
        "\n",
        "    # Check if the required columns ('x', 'y', 'z') exist\n",
        "    columns_to_normalize = ['x', 'y', 'z']\n",
        "    if all(col in sensor_data.columns for col in columns_to_normalize):\n",
        "        # Apply normalization\n",
        "        sensor_data[columns_to_normalize] = normalize_data(sensor_data[columns_to_normalize])\n",
        "\n",
        "        # Print the result after normalization\n",
        "        print(\"Data after normalization:\")\n",
        "        print(sensor_data[['time', 'x', 'y', 'z']].head())\n",
        "    else:\n",
        "        print(\"Columns 'x', 'y', 'z' are not found for normalization.\")\n",
        "\n",
        "# Sample data for testing\n",
        "data = {'sensor_1': pd.DataFrame({\n",
        "    'time': pd.date_range(start='2024-10-16', periods=5, freq='0.1s'),\n",
        "    'x': [1, 2, 3, 4, 5],\n",
        "    'y': [2, 3, 4, 5, 6],\n",
        "    'z': [3, 4, 5, 6, 7]\n",
        "})}\n",
        "\n",
        "# Apply normalization on the sensor data\n",
        "for sensor, sensor_data in data.items():\n",
        "    normalize_step(sensor_data)\n",
        "\n",
        "# Check the number of rows in the original dataset\n",
        "print(f\"Number of rows in the original dataset: {len(sensor_data)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiquhtX0eADe",
        "outputId": "89bc0a4b-1a36-4ddc-b511-a97e4276d375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Normalization\n",
            "Data after normalization:\n",
            "                     time     x     y     z\n",
            "0 2024-10-16 00:00:00.000  0.00  0.00  0.00\n",
            "1 2024-10-16 00:00:00.100  0.25  0.25  0.25\n",
            "2 2024-10-16 00:00:00.200  0.50  0.50  0.50\n",
            "3 2024-10-16 00:00:00.300  0.75  0.75  0.75\n",
            "4 2024-10-16 00:00:00.400  1.00  1.00  1.00\n",
            "Number of rows in the original dataset: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming `sensor_data` is your DataFrame after normalization\n",
        "\n",
        "# Step 1: Ensure 'time' is in datetime format if not already\n",
        "sensor_data['time'] = pd.to_datetime(sensor_data['time'], unit='ns')  # Adjust 'unit' as per your data if needed\n",
        "\n",
        "# Step 2: Set 'time' as the index\n",
        "sensor_data.set_index('time', inplace=True)\n",
        "\n",
        "# Step 3: Resample the data at a specific frequency (e.g., 100ms)\n",
        "freq = '100ms'  # Change this to your desired frequency (e.g., '1s' for 1 second intervals)\n",
        "sensor_data_resampled = sensor_data.resample(freq).interpolate(method='linear')\n",
        "\n",
        "# Step 4: Check the data after resampling\n",
        "print(f\"Resampled data sample:\\n{sensor_data_resampled.head()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3q-tnsNEh5wv",
        "outputId": "f7a401bf-6c8e-4a85-e9bd-555198242626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resampled data sample:\n",
            "                            x     y     z\n",
            "time                                     \n",
            "2024-10-16 00:00:00.000  0.00  0.00  0.00\n",
            "2024-10-16 00:00:00.100  0.25  0.25  0.25\n",
            "2024-10-16 00:00:00.200  0.50  0.50  0.50\n",
            "2024-10-16 00:00:00.300  0.75  0.75  0.75\n",
            "2024-10-16 00:00:00.400  1.00  1.00  1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming `sensor_data_resampled` is your DataFrame after resampling\n",
        "\n",
        "# Step 1: Apply a low-pass filter (Moving Average) to the sensor data\n",
        "window_size = 5  # Adjust this window size based on the level of smoothing required\n",
        "sensor_data_filtered = sensor_data_resampled.rolling(window=window_size, min_periods=1).mean()\n",
        "\n",
        "# Alternative: Exponential Moving Average (smoothing)\n",
        "# alpha = 0.1  # smoothing factor (0 < alpha < 1)\n",
        "# sensor_data_filtered = sensor_data_resampled.ewm(alpha=alpha, adjust=False).mean()\n",
        "\n",
        "# Step 2: Check the data after noise reduction\n",
        "print(f\"Data after noise reduction:\\n{sensor_data_filtered.head()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVbyjlOpiGZQ",
        "outputId": "d35d6e51-5fc4-4296-ec7b-6765d4ca45f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data after noise reduction:\n",
            "                             x      y      z\n",
            "time                                        \n",
            "2024-10-16 00:00:00.000  0.000  0.000  0.000\n",
            "2024-10-16 00:00:00.100  0.125  0.125  0.125\n",
            "2024-10-16 00:00:00.200  0.250  0.250  0.250\n",
            "2024-10-16 00:00:00.300  0.375  0.375  0.375\n",
            "2024-10-16 00:00:00.400  0.500  0.500  0.500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Assuming sensor_data_filtered is the data after noise reduction\n",
        "\n",
        "def extract_features(sensor_data):\n",
        "    features = {}\n",
        "\n",
        "    # Time-domain features\n",
        "    features['mean_x'] = sensor_data['x'].mean()\n",
        "    features['mean_y'] = sensor_data['y'].mean()\n",
        "    features['mean_z'] = sensor_data['z'].mean()\n",
        "\n",
        "    features['std_x'] = sensor_data['x'].std()\n",
        "    features['std_y'] = sensor_data['y'].std()\n",
        "    features['std_z'] = sensor_data['z'].std()\n",
        "\n",
        "    features['max_x'] = sensor_data['x'].max()\n",
        "    features['max_y'] = sensor_data['y'].max()\n",
        "    features['max_z'] = sensor_data['z'].max()\n",
        "\n",
        "    features['min_x'] = sensor_data['x'].min()\n",
        "    features['min_y'] = sensor_data['y'].min()\n",
        "    features['min_z'] = sensor_data['z'].min()\n",
        "\n",
        "    features['range_x'] = features['max_x'] - features['min_x']\n",
        "    features['range_y'] = features['max_y'] - features['min_y']\n",
        "    features['range_z'] = features['max_z'] - features['min_z']\n",
        "\n",
        "    features['skew_x'] = skew(sensor_data['x'])\n",
        "    features['skew_y'] = skew(sensor_data['y'])\n",
        "    features['skew_z'] = skew(sensor_data['z'])\n",
        "\n",
        "    features['kurtosis_x'] = kurtosis(sensor_data['x'])\n",
        "    features['kurtosis_y'] = kurtosis(sensor_data['y'])\n",
        "    features['kurtosis_z'] = kurtosis(sensor_data['z'])\n",
        "\n",
        "    # RMS (Root Mean Square)\n",
        "    features['rms_x'] = np.sqrt(np.mean(np.square(sensor_data['x'])))\n",
        "    features['rms_y'] = np.sqrt(np.mean(np.square(sensor_data['y'])))\n",
        "    features['rms_z'] = np.sqrt(np.mean(np.square(sensor_data['z'])))\n",
        "\n",
        "    # Velocity (Cumulative Sum of Acceleration)\n",
        "    features['velocity_x'] = np.cumsum(sensor_data['x'])\n",
        "    features['velocity_y'] = np.cumsum(sensor_data['y'])\n",
        "    features['velocity_z'] = np.cumsum(sensor_data['z'])\n",
        "\n",
        "    # Jerk (Rate of change of acceleration)\n",
        "    jerk_x = np.diff(sensor_data['x'], n=1)\n",
        "    jerk_y = np.diff(sensor_data['y'], n=1)\n",
        "    jerk_z = np.diff(sensor_data['z'], n=1)\n",
        "    features['jerk_x'] = np.mean(np.abs(jerk_x))\n",
        "    features['jerk_y'] = np.mean(np.abs(jerk_y))\n",
        "    features['jerk_z'] = np.mean(np.abs(jerk_z))\n",
        "\n",
        "    return features\n",
        "\n",
        "# Apply feature extraction\n",
        "extracted_features = extract_features(sensor_data_filtered)\n",
        "\n",
        "# Convert extracted features into a DataFrame\n",
        "features_df = pd.DataFrame([extracted_features])\n",
        "\n",
        "# Show extracted features\n",
        "print(f\"Extracted Features:\\n{features_df}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mciRCgqibio",
        "outputId": "50bff404-e66f-4d34-c597-d08af92ec947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Features:\n",
            "   mean_x  mean_y  mean_z     std_x     std_y     std_z  max_x  max_y  max_z  \\\n",
            "0    0.25    0.25    0.25  0.197642  0.197642  0.197642    0.5    0.5    0.5   \n",
            "\n",
            "   min_x  ...  kurtosis_z     rms_x     rms_y     rms_z  \\\n",
            "0    0.0  ...        -1.3  0.306186  0.306186  0.306186   \n",
            "\n",
            "                                          velocity_x  \\\n",
            "0  time\n",
            "2024-10-16 00:00:00.000    0.000\n",
            "2024-10-...   \n",
            "\n",
            "                                          velocity_y  \\\n",
            "0  time\n",
            "2024-10-16 00:00:00.000    0.000\n",
            "2024-10-...   \n",
            "\n",
            "                                          velocity_z  jerk_x  jerk_y  jerk_z  \n",
            "0  time\n",
            "2024-10-16 00:00:00.000    0.000\n",
            "2024-10-...   0.125   0.125   0.125  \n",
            "\n",
            "[1 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# Assuming sensor_data_filtered is the data after noise reduction\n",
        "\n",
        "def extract_features(sensor_data):\n",
        "    features = {}\n",
        "\n",
        "    # Time-domain features\n",
        "    features['mean_x'] = sensor_data['x'].mean()\n",
        "    features['mean_y'] = sensor_data['y'].mean()\n",
        "    features['mean_z'] = sensor_data['z'].mean()\n",
        "\n",
        "    features['std_x'] = sensor_data['x'].std()\n",
        "    features['std_y'] = sensor_data['y'].std()\n",
        "    features['std_z'] = sensor_data['z'].std()\n",
        "\n",
        "    features['max_x'] = sensor_data['x'].max()\n",
        "    features['max_y'] = sensor_data['y'].max()\n",
        "    features['max_z'] = sensor_data['z'].max()\n",
        "\n",
        "    features['min_x'] = sensor_data['x'].min()\n",
        "    features['min_y'] = sensor_data['y'].min()\n",
        "    features['min_z'] = sensor_data['z'].min()\n",
        "\n",
        "    features['range_x'] = features['max_x'] - features['min_x']\n",
        "    features['range_y'] = features['max_y'] - features['min_y']\n",
        "    features['range_z'] = features['max_z'] - features['min_z']\n",
        "\n",
        "    features['skew_x'] = skew(sensor_data['x'])\n",
        "    features['skew_y'] = skew(sensor_data['y'])\n",
        "    features['skew_z'] = skew(sensor_data['z'])\n",
        "\n",
        "    features['kurtosis_x'] = kurtosis(sensor_data['x'])\n",
        "    features['kurtosis_y'] = kurtosis(sensor_data['y'])\n",
        "    features['kurtosis_z'] = kurtosis(sensor_data['z'])\n",
        "\n",
        "    # RMS (Root Mean Square)\n",
        "    features['rms_x'] = np.sqrt(np.mean(np.square(sensor_data['x'])))\n",
        "    features['rms_y'] = np.sqrt(np.mean(np.square(sensor_data['y'])))\n",
        "    features['rms_z'] = np.sqrt(np.mean(np.square(sensor_data['z'])))\n",
        "\n",
        "    # Velocity (Cumulative Sum of Acceleration)\n",
        "    features['velocity_x'] = np.cumsum(sensor_data['x'])\n",
        "    features['velocity_y'] = np.cumsum(sensor_data['y'])\n",
        "    features['velocity_z'] = np.cumsum(sensor_data['z'])\n",
        "\n",
        "    # Jerk (Rate of change of acceleration)\n",
        "    jerk_x = np.diff(sensor_data['x'], n=1)\n",
        "    jerk_y = np.diff(sensor_data['y'], n=1)\n",
        "    jerk_z = np.diff(sensor_data['z'], n=1)\n",
        "    features['jerk_x'] = np.mean(np.abs(jerk_x))\n",
        "    features['jerk_y'] = np.mean(np.abs(jerk_y))\n",
        "    features['jerk_z'] = np.mean(np.abs(jerk_z))\n",
        "\n",
        "    # Trajectory Analysis\n",
        "    # Total displacement (Euclidean distance between consecutive points)\n",
        "    displacement = np.sqrt(np.diff(sensor_data['x'])**2 + np.diff(sensor_data['y'])**2 + np.diff(sensor_data['z'])**2)\n",
        "    features['total_displacement'] = np.sum(displacement)\n",
        "\n",
        "    # Mean displacement (average distance between consecutive points)\n",
        "    features['mean_displacement'] = np.mean(displacement)\n",
        "\n",
        "    # Total distance traveled (Cumulative sum of displacement)\n",
        "    features['total_distance'] = np.sum(displacement)\n",
        "\n",
        "    return features\n",
        "\n",
        "# Apply feature extraction\n",
        "extracted_features = extract_features(sensor_data_filtered)\n",
        "\n",
        "# Convert extracted features into a DataFrame\n",
        "features_df = pd.DataFrame([extracted_features])\n",
        "\n",
        "# Show extracted features\n",
        "print(f\"Extracted Features:\\n{features_df}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ9qYqhiit9M",
        "outputId": "1b776960-4a23-4c60-8cf5-47f4f937443b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Features:\n",
            "   mean_x  mean_y  mean_z     std_x     std_y     std_z  max_x  max_y  max_z  \\\n",
            "0    0.25    0.25    0.25  0.197642  0.197642  0.197642    0.5    0.5    0.5   \n",
            "\n",
            "   min_x  ...     rms_z                                         velocity_x  \\\n",
            "0    0.0  ...  0.306186  time\n",
            "2024-10-16 00:00:00.000    0.000\n",
            "2024-10-...   \n",
            "\n",
            "                                          velocity_y  \\\n",
            "0  time\n",
            "2024-10-16 00:00:00.000    0.000\n",
            "2024-10-...   \n",
            "\n",
            "                                          velocity_z  jerk_x  jerk_y  jerk_z  \\\n",
            "0  time\n",
            "2024-10-16 00:00:00.000    0.000\n",
            "2024-10-...   0.125   0.125   0.125   \n",
            "\n",
            "   total_displacement  mean_displacement  total_distance  \n",
            "0            0.866025           0.216506        0.866025  \n",
            "\n",
            "[1 rows x 33 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming sensor_data_filtered is your original data\n",
        "\n",
        "def jittering(sensor_data, noise_factor=0.01):\n",
        "    \"\"\" Add small random noise to the data to simulate sensor variations. \"\"\"\n",
        "    noise = np.random.normal(0, noise_factor, sensor_data.shape)  # Create random noise\n",
        "    augmented_data = sensor_data + noise\n",
        "    return augmented_data\n",
        "\n",
        "def scaling(sensor_data, scale_factor=1.1):\n",
        "    \"\"\" Adjust the amplitude of the sensor readings to simulate speed variations. \"\"\"\n",
        "    augmented_data = sensor_data * scale_factor  # Scale the sensor data\n",
        "    return augmented_data\n",
        "\n",
        "def time_warping(sensor_data, warp_factor=0.2):\n",
        "    \"\"\" Stretch or compress the time axis to simulate different motion patterns. \"\"\"\n",
        "    # Create a time warp factor for each axis\n",
        "    time_warp_x = np.interp(np.arange(0, len(sensor_data), warp_factor), np.arange(0, len(sensor_data)), sensor_data['x'])\n",
        "    time_warp_y = np.interp(np.arange(0, len(sensor_data), warp_factor), np.arange(0, len(sensor_data)), sensor_data['y'])\n",
        "    time_warp_z = np.interp(np.arange(0, len(sensor_data), warp_factor), np.arange(0, len(sensor_data)), sensor_data['z'])\n",
        "\n",
        "    # Create new DataFrame with warped time data\n",
        "    augmented_data = pd.DataFrame({\n",
        "        'x': time_warp_x,\n",
        "        'y': time_warp_y,\n",
        "        'z': time_warp_z\n",
        "    })\n",
        "    return augmented_data\n",
        "\n",
        "def augment_data(sensor_data, jitter=True, scale=True, time_warp=True):\n",
        "    \"\"\" Apply all augmentation techniques and return augmented dataset. \"\"\"\n",
        "    augmented_data = sensor_data.copy()\n",
        "\n",
        "    if jitter:\n",
        "        augmented_data = jittering(augmented_data)\n",
        "\n",
        "    if scale:\n",
        "        augmented_data = scaling(augmented_data)\n",
        "\n",
        "    if time_warp:\n",
        "        augmented_data = time_warping(augmented_data)\n",
        "\n",
        "    return augmented_data\n",
        "\n",
        "# Example: Apply data augmentation to your filtered sensor data\n",
        "augmented_sensor_data = augment_data(sensor_data_filtered)\n",
        "\n",
        "# Display the augmented data (optional)\n",
        "print(augmented_sensor_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h0WtqYIjMP-",
        "outputId": "10f61cb8-1874-488c-8d27-c20baa902ed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          x         y         z\n",
            "0 -0.012872  0.001852 -0.002581\n",
            "1  0.020010  0.025585  0.026646\n",
            "2  0.052891  0.049319  0.055873\n",
            "3  0.085773  0.073052  0.085099\n",
            "4  0.118654  0.096786  0.114326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming your original sensor data looks like this\n",
        "sensor_data = pd.DataFrame({\n",
        "    'x': [-0.012872, 0.020010, 0.052891, 0.085773, 0.118654],\n",
        "    'y': [0.001852, 0.025585, 0.049319, 0.073052, 0.096786],\n",
        "    'z': [-0.002581, 0.026646, 0.055873, 0.085099, 0.114326]\n",
        "})\n",
        "\n",
        "def jittering(sensor_data, noise_factor=0.01):\n",
        "    \"\"\" Add small random noise to the data to simulate sensor variations. \"\"\"\n",
        "    noise = np.random.normal(0, noise_factor, sensor_data.shape)  # Create random noise\n",
        "    augmented_data = sensor_data + noise\n",
        "    return augmented_data\n",
        "\n",
        "def scaling(sensor_data, scale_factor=1.1):\n",
        "    \"\"\" Adjust the amplitude of the sensor readings to simulate speed variations. \"\"\"\n",
        "    augmented_data = sensor_data * scale_factor  # Scale the sensor data\n",
        "    return augmented_data\n",
        "\n",
        "def time_warping(sensor_data, warp_factor=0.2):\n",
        "    \"\"\" Stretch or compress the time axis to simulate different motion patterns. \"\"\"\n",
        "    # Create a time warp factor for each axis\n",
        "    time_warp_x = np.interp(np.arange(0, len(sensor_data), warp_factor), np.arange(0, len(sensor_data)), sensor_data['x'])\n",
        "    time_warp_y = np.interp(np.arange(0, len(sensor_data), warp_factor), np.arange(0, len(sensor_data)), sensor_data['y'])\n",
        "    time_warp_z = np.interp(np.arange(0, len(sensor_data), warp_factor), np.arange(0, len(sensor_data)), sensor_data['z'])\n",
        "\n",
        "    # Create new DataFrame with warped time data\n",
        "    augmented_data = pd.DataFrame({\n",
        "        'x': time_warp_x,\n",
        "        'y': time_warp_y,\n",
        "        'z': time_warp_z\n",
        "    })\n",
        "    return augmented_data\n",
        "\n",
        "def augment_data(sensor_data, jitter=True, scale=True, time_warp=True):\n",
        "    \"\"\" Apply all augmentation techniques and return augmented dataset. \"\"\"\n",
        "    augmented_data = sensor_data.copy()\n",
        "\n",
        "    if jitter:\n",
        "        augmented_data = jittering(augmented_data)\n",
        "\n",
        "    if scale:\n",
        "        augmented_data = scaling(augmented_data)\n",
        "\n",
        "    if time_warp:\n",
        "        augmented_data = time_warping(augmented_data)\n",
        "\n",
        "    return augmented_data\n",
        "\n",
        "# Example: Apply data augmentation to your original sensor data\n",
        "augmented_sensor_data = augment_data(sensor_data)\n",
        "\n",
        "# Display the augmented data (optional)\n",
        "print(\"Original Data:\\n\", sensor_data)\n",
        "print(\"\\nAugmented Data:\\n\", augmented_sensor_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKCDy_kVlej-",
        "outputId": "f896fc66-9519-400e-98f6-298dd0900f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Data:\n",
            "           x         y         z\n",
            "0 -0.012872  0.001852 -0.002581\n",
            "1  0.020010  0.025585  0.026646\n",
            "2  0.052891  0.049319  0.055873\n",
            "3  0.085773  0.073052  0.085099\n",
            "4  0.118654  0.096786  0.114326\n",
            "\n",
            "Augmented Data:\n",
            "            x         y         z\n",
            "0  -0.008943  0.008494 -0.002401\n",
            "1  -0.002353  0.014367  0.004700\n",
            "2   0.004237  0.020240  0.011801\n",
            "3   0.010828  0.026113  0.018901\n",
            "4   0.017418  0.031986  0.026002\n",
            "5   0.024008  0.037859  0.033103\n",
            "6   0.028411  0.039688  0.039378\n",
            "7   0.032813  0.041517  0.045652\n",
            "8   0.037215  0.043346  0.051927\n",
            "9   0.041618  0.045175  0.058202\n",
            "10  0.046020  0.047004  0.064476\n",
            "11  0.056758  0.054599  0.074513\n",
            "12  0.067496  0.062194  0.084550\n",
            "13  0.078234  0.069789  0.094587\n",
            "14  0.088972  0.077384  0.104624\n",
            "15  0.099711  0.084979  0.114661\n",
            "16  0.106954  0.086788  0.118695\n",
            "17  0.114197  0.088597  0.122729\n",
            "18  0.121441  0.090406  0.126763\n",
            "19  0.128684  0.092215  0.130797\n",
            "20  0.135927  0.094025  0.134831\n",
            "21  0.135927  0.094025  0.134831\n",
            "22  0.135927  0.094025  0.134831\n",
            "23  0.135927  0.094025  0.134831\n",
            "24  0.135927  0.094025  0.134831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Feature extraction function (same as before)\n",
        "def extract_features(sensor_data):\n",
        "    features = {}\n",
        "    features['mean_x'] = sensor_data['x'].mean()\n",
        "    features['mean_y'] = sensor_data['y'].mean()\n",
        "    features['mean_z'] = sensor_data['z'].mean()\n",
        "\n",
        "    features['std_x'] = sensor_data['x'].std()\n",
        "    features['std_y'] = sensor_data['y'].std()\n",
        "    features['std_z'] = sensor_data['z'].std()\n",
        "\n",
        "    features['rms_x'] = np.sqrt(np.mean(np.square(sensor_data['x'])))\n",
        "    features['rms_y'] = np.sqrt(np.mean(np.square(sensor_data['y'])))\n",
        "    features['rms_z'] = np.sqrt(np.mean(np.square(sensor_data['z'])))\n",
        "\n",
        "    features['skew_x'] = skew(sensor_data['x'])\n",
        "    features['skew_y'] = skew(sensor_data['y'])\n",
        "    features['skew_z'] = skew(sensor_data['z'])\n",
        "\n",
        "    features['kurtosis_x'] = kurtosis(sensor_data['x'])\n",
        "    features['kurtosis_y'] = kurtosis(sensor_data['y'])\n",
        "    features['kurtosis_z'] = kurtosis(sensor_data['z'])\n",
        "\n",
        "    return features\n",
        "\n",
        "# Assuming sensor_data is a DataFrame containing 'x', 'y', 'z', and 'time'\n",
        "# Example data\n",
        "sensor_data = pd.DataFrame({\n",
        "    'x': [-0.012872, 0.020010, 0.052891, 0.085773, 0.118654],\n",
        "    'y': [0.001852, 0.025585, 0.049319, 0.073052, 0.096786],\n",
        "    'z': [-0.002581, 0.026646, 0.055873, 0.085099, 0.114326],\n",
        "    'time': [0, 1, 2, 3, 4]  # assuming 1-second intervals\n",
        "})\n",
        "\n",
        "# Extract features\n",
        "features = extract_features(sensor_data)\n",
        "features_df = pd.DataFrame([features])\n",
        "\n",
        "# Assume we have corresponding ground truth distance data (for training)\n",
        "# Example ground truth distances (in meters)\n",
        "ground_truth_distance = [0.01, 0.05, 0.15, 0.35, 0.60]  # These should be actual measurements\n",
        "\n",
        "# Create training data\n",
        "X = features_df  # Input features\n",
        "y = ground_truth_distance  # Ground truth distances\n",
        "\n",
        "# Split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Predicted Distances: {y_pred}')\n",
        "print(f'Actual Distances: {y_test}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "pT1FGlczmD2z",
        "outputId": "4f7c3298-ef6f-4481-9b01-851473350ee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [1, 5]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-bf23d67039b8>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Split into train and test datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Train a Random Forest Regressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2780\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2782\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2784\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 5]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Feature extraction function (same as before)\n",
        "def extract_features(sensor_data):\n",
        "    features = {}\n",
        "    features['mean_x'] = sensor_data['x'].mean()\n",
        "    features['mean_y'] = sensor_data['y'].mean()\n",
        "    features['mean_z'] = sensor_data['z'].mean()\n",
        "\n",
        "    features['std_x'] = sensor_data['x'].std()\n",
        "    features['std_y'] = sensor_data['y'].std()\n",
        "    features['std_z'] = sensor_data['z'].std()\n",
        "\n",
        "    features['rms_x'] = np.sqrt(np.mean(np.square(sensor_data['x'])))\n",
        "    features['rms_y'] = np.sqrt(np.mean(np.square(sensor_data['y'])))\n",
        "    features['rms_z'] = np.sqrt(np.mean(np.square(sensor_data['z'])))\n",
        "\n",
        "    features['skew_x'] = skew(sensor_data['x'])\n",
        "    features['skew_y'] = skew(sensor_data['y'])\n",
        "    features['skew_z'] = skew(sensor_data['z'])\n",
        "\n",
        "    features['kurtosis_x'] = kurtosis(sensor_data['x'])\n",
        "    features['kurtosis_y'] = kurtosis(sensor_data['y'])\n",
        "    features['kurtosis_z'] = kurtosis(sensor_data['z'])\n",
        "\n",
        "    return features\n",
        "\n",
        "# Example sensor data: splitting it into windows (for illustration)\n",
        "sensor_data = pd.DataFrame({\n",
        "    'x': [-0.012872, 0.020010, 0.052891, 0.085773, 0.118654, 0.15, 0.18, 0.25],\n",
        "    'y': [0.001852, 0.025585, 0.049319, 0.073052, 0.096786, 0.12, 0.15, 0.18],\n",
        "    'z': [-0.002581, 0.026646, 0.055873, 0.085099, 0.114326, 0.13, 0.16, 0.2],\n",
        "})\n",
        "\n",
        "# Let's simulate a few more data points and calculate the features over 2-second windows\n",
        "window_size = 2  # You can adjust this window size\n",
        "num_windows = len(sensor_data) // window_size\n",
        "\n",
        "# Prepare the feature matrix (X) and target (y)\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(num_windows):\n",
        "    start = i * window_size\n",
        "    end = start + window_size\n",
        "    window_data = sensor_data[start:end]\n",
        "    features = extract_features(window_data)\n",
        "    X.append(features)\n",
        "\n",
        "    # Assuming you have corresponding distance values (replace with actual ground truth)\n",
        "    distance = 0.1 * (i + 1)  # Dummy distances (in meters)\n",
        "    y.append(distance)\n",
        "\n",
        "# Convert X and y to DataFrames\n",
        "X = pd.DataFrame(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Predicted Distances: {y_pred}')\n",
        "print(f'Actual Distances: {y_test}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thGYHly1mmGG",
        "outputId": "c5a1ed5c-bb8e-47e8-e7d9-5490eb8a93fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.00025600000000000313\n",
            "Predicted Distances: [0.216]\n",
            "Actual Distances: [0.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Example: Already extracted features from the sensor data\n",
        "# Assume that sensor_data_filtered is already processed and features have been extracted\n",
        "# For illustration, here's a simulated feature DataFrame (replace with your actual extracted features)\n",
        "X = pd.DataFrame({\n",
        "    'mean_x': [-0.01, 0.02, 0.05, 0.08, 0.12],\n",
        "    'mean_y': [0.001, 0.025, 0.049, 0.073, 0.096],\n",
        "    'mean_z': [-0.002, 0.026, 0.055, 0.085, 0.114],\n",
        "    'std_x': [0.03, 0.02, 0.025, 0.035, 0.04],\n",
        "    'std_y': [0.01, 0.02, 0.015, 0.02, 0.025],\n",
        "    'std_z': [0.005, 0.01, 0.02, 0.01, 0.015],\n",
        "    'rms_x': [0.04, 0.05, 0.06, 0.07, 0.08],\n",
        "    'rms_y': [0.01, 0.015, 0.02, 0.025, 0.03],\n",
        "    'rms_z': [0.02, 0.025, 0.03, 0.035, 0.04],\n",
        "    'skew_x': [0.1, 0.2, 0.1, 0.3, 0.4],\n",
        "    'skew_y': [0.05, 0.1, 0.15, 0.2, 0.25],\n",
        "    'skew_z': [0.08, 0.12, 0.18, 0.14, 0.3],\n",
        "    'kurtosis_x': [3, 2.8, 3.2, 3.5, 3.6],\n",
        "    'kurtosis_y': [3.1, 2.9, 3.3, 3.4, 3.7],\n",
        "    'kurtosis_z': [3.2, 3, 3.4, 3.6, 3.8]\n",
        "})\n",
        "\n",
        "# Corresponding distance values (y) for each feature set in X\n",
        "# These should correspond to each window/segment from the sensor data\n",
        "y = np.array([0.1, 0.2, 0.3, 0.4, 0.5])  # Replace with actual distance ground truth\n",
        "\n",
        "# Split into train and test datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Predicted Distances: {y_pred}')\n",
        "print(f'Actual Distances: {y_test}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSUWRhCmmfh5",
        "outputId": "862832c7-6ac9-4e61-ae48-317b287e8e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.002025000000000006\n",
            "Predicted Distances: [0.245]\n",
            "Actual Distances: [0.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Train an SVR model\n",
        "svr_model = SVR(kernel='rbf')  # Radial Basis Function kernel, you can try 'linear', 'poly', etc.\n",
        "svr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_svr = svr_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
        "print(f'Mean Squared Error (SVR): {mse_svr}')\n",
        "print(f'Predicted Distances (SVR): {y_pred_svr}')\n",
        "print(f'Actual Distances: {y_test}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJdesu1lnF6q",
        "outputId": "06cab8b5-fc50-4fc1-cb29-fcd17d7fc772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (SVR): 0.001857059946457109\n",
            "Predicted Distances (SVR): [0.24309362]\n",
            "Actual Distances: [0.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Train an XGBoost model\n",
        "xgboost_model = xgb.XGBRegressor(objective ='reg:squarederror', n_estimators=100, random_state=42)\n",
        "xgboost_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_xgb = xgboost_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "print(f'Mean Squared Error (XGBoost): {mse_xgb}')\n",
        "print(f'Predicted Distances (XGBoost): {y_pred_xgb}')\n",
        "print(f'Actual Distances: {y_test}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6frXZKqrnILJ",
        "outputId": "51c1f97f-7c80-495b-d0c2-a9d09f6836d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (XGBoost): 0.009796267385560697\n",
            "Predicted Distances (XGBoost): [0.1010239]\n",
            "Actual Distances: [0.2]\n"
          ]
        }
      ]
    }
  ]
}